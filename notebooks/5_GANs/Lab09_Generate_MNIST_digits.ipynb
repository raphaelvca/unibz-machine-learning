{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 09 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import tensorflow\n",
    "from tensorflow.keras.datasets import imdb, mnist\n",
    "# from tensorflow.keras.utils import np_utils\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN, Input\n",
    "# from tensorflow.keras.layers.advanced_activations import LeakyReLU\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import scipy\n",
    "import random\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from scipy import stats\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE 1 : MNIST GAN - Learn to generate MNIST digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) =  mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescale data since we are using ReLU activations. <b>WHY ?</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BUILD MODEL\n",
    "\n",
    "We are using LeakyReLU activations. \n",
    "\n",
    "We will build\n",
    "\n",
    "a.) Generator\n",
    "b.) Discriminator\n",
    "c.) GAN\n",
    "\n",
    "as feedforwards with multiple layers, dropout and LeakyReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2720aa4f0833>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#GAN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "adam = Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "\n",
    "#GENERATOR\n",
    "g = Sequential()\n",
    "#Build your generator - noise_dim -> 256 -> 512 ->1024 ->784. LeakyRelU(0.2), adam\n",
    "\n",
    "\n",
    "#DISCRIMINATOR\n",
    "#Build your discriminator - 784 -> 1024 -> 512 -> 256 -> 1. LeakyRelu(0.2), adam\n",
    "\n",
    "\n",
    "#GAN\n",
    "d.trainable = False\n",
    "inputs = Input(shape=(z_dim, ))\n",
    "hidden = g(inputs)\n",
    "output = d(hidden)\n",
    "gan = Model(inputs, output)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us write some visualization code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(losses):\n",
    "    \"\"\"\n",
    "    @losses.keys():\n",
    "        0: loss\n",
    "        1: accuracy\n",
    "    \"\"\"\n",
    "    d_loss = [v[0] for v in losses[\"D\"]]\n",
    "    g_loss = [v[0] for v in losses[\"G\"]]\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(d_loss, label=\"Discriminator loss\")\n",
    "    plt.plot(g_loss, label=\"Generator loss\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_generated(n_ex=10, dim=(1, 10), figsize=(12, 2)):\n",
    "    noise = np.random.normal(0, 1, size=(n_ex, z_dim))\n",
    "    generated_images = g.predict(noise)\n",
    "    generated_images = generated_images.reshape(n_ex, 28, 28)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generated_images[i], interpolation='nearest', cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> TRAIN THE MODEL </b>\n",
    "\n",
    "Generate noise, feed into generator, compare them with discriminator, train the GAN and REPEAT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\"D\":[], \"G\":[]}\n",
    "\n",
    "def train(epochs=1, plt_frq=1, BATCH_SIZE=128):\n",
    "    batchCount = int(X_train.shape[0] / BATCH_SIZE)\n",
    "    print('Epochs:', epochs)\n",
    "    print('Batch size:', BATCH_SIZE)\n",
    "    print('Batches per epoch:', batchCount)\n",
    "    \n",
    "    for e in tqdm_notebook(range(1, epochs+1)):\n",
    "        if e == 1 or e%plt_frq == 0:\n",
    "            print('-'*15, 'Epoch %d' % e, '-'*15)\n",
    "        for _ in range(batchCount):  # tqdm_notebook(range(batchCount), leave=False):\n",
    "            # Create a batch by drawing random index numbers from the training set\n",
    "            image_batch = X_train[np.random.randint(0, X_train.shape[0], size=BATCH_SIZE)]\n",
    "            \n",
    "            # Create noise vectors for the generator\n",
    "            noise = np.random.normal(0, 1, size=(BATCH_SIZE, z_dim))\n",
    "            \n",
    "            # Generate the images from the noise\n",
    "            generated_images = g.predict(noise)\n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            \n",
    "            # Create Y labels (0 for fake and 1 for real).\n",
    "            ##YOUR CODE HERE ~2lines###\n",
    "\n",
    "            # Train gan \n",
    "            ##YOUR CODE HERE ~6lines###\n",
    "            \n",
    "            \n",
    "            ##Train discriminator (create noise and labels)\n",
    "            ##YOUR CODE HERE ~4lines###\n",
    "            \n",
    "\n",
    "        # Only store losses from final\n",
    "        losses[\"D\"].append(d_loss)\n",
    "        losses[\"G\"].append(g_loss)\n",
    "\n",
    "        # Update the plots\n",
    "        if e == 1 or e%plt_frq == 0:\n",
    "            plot_generated()\n",
    "    plot_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(epochs=200, plt_frq=40, BATCH_SIZE=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
