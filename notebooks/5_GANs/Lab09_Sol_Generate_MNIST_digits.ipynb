{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import tensorflow\n",
    "from tensorflow.keras.datasets import imdb, mnist\n",
    "# from tensorflow.keras.utils import np_utils\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN, Input\n",
    "# from tensorflow.keras.layers.advanced_activations import LeakyReLU\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import scipy\n",
    "import random\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from scipy import stats\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE 1 : MNIST GAN - Learn to generate MNIST digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) =  mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescale data since we are using ReLU activations. <b>WHY ?</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BUILD MODEL\n",
    "\n",
    "We are using LeakyReLU activations. \n",
    "\n",
    "We will build\n",
    "\n",
    "a.) Generator\n",
    "b.) Discriminator\n",
    "c.) GAN\n",
    "\n",
    "as feedforwards with multiple layers, dropout and LeakyReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Adam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e15510a11a99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#@title\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0madam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0002\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m DefaultConv2D = partial(keras.layers.Conv2D,\n\u001b[0;32m      5\u001b[0m                         kernel_size=3, activation='relu', padding=\"SAME\")\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Adam' is not defined"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "adam = Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                        kernel_size=3, activation='relu', padding=\"SAME\")\n",
    "\n",
    "\n",
    "#GENERATOR\n",
    "g = Sequential()\n",
    "#Build your generator - noise_dim -> 256 -> 512 ->1024 ->784. LeakyRelU(0.2), adam\n",
    "g.add(Dense(256, input_dim=z_dim, activation='selu'))\n",
    "g.add(DefaultConv2D(filters=128))\n",
    "g.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "g.add(DefaultConv2D(filters=256))\n",
    "g.add(keras.layers.MaxPooling2D(pool_size=2))\n",
    "g.add(keras.layers.Flatten())\n",
    "g.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "g.add(keras.layers.Dropout(0.5))\n",
    "g.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "g.add(keras.layers.Dropout(0.5))\n",
    "g.add(Dense(32, activation='sigmoid'))  # Values between 0 and 1\n",
    "g.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#DISCRIMINATOR\n",
    "#Build your discriminator - 784 -> 1024 -> 512 -> 256 -> 1. LeakyRelu(0.2), adam\n",
    "d = Sequential()\n",
    "d.add(Dense(1024, input_dim=784, activation='selu'))\n",
    "d.add(Dropout(0.3))\n",
    "d.add(Dense(512, activation='selu'))\n",
    "d.add(Dropout(0.3))\n",
    "d.add(Dense(256, activation='selu'))\n",
    "d.add(Dropout(0.3))\n",
    "d.add(Dense(1, activation='sigmoid'))  # Values between 0 and 1\n",
    "d.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#GAN\n",
    "d.trainable = False\n",
    "inputs = Input(shape=(z_dim, ))\n",
    "hidden = g(inputs)\n",
    "output = d(hidden)\n",
    "gan = Model(inputs, output)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us write some visualization code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(losses):\n",
    "    \"\"\"\n",
    "    @losses.keys():\n",
    "        0: loss\n",
    "        1: accuracy\n",
    "    \"\"\"\n",
    "    d_loss = [v[0] for v in losses[\"D\"]]\n",
    "    g_loss = [v[0] for v in losses[\"G\"]]\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(d_loss, label=\"Discriminator loss\")\n",
    "    plt.plot(g_loss, label=\"Generator loss\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_generated(n_ex=10, dim=(1, 10), figsize=(12, 2)):\n",
    "    noise = np.random.normal(0, 1, size=(n_ex, z_dim))\n",
    "    generated_images = g.predict(noise)\n",
    "    generated_images = generated_images.reshape(n_ex, 28, 28)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generated_images[i], interpolation='nearest', cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> TRAIN THE MODEL </b>\n",
    "\n",
    "Generate noise, feed into generator, compare them with discriminator, train the GAN and REPEAT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\"D\":[], \"G\":[]}\n",
    "\n",
    "def train(epochs=1, plt_frq=1, BATCH_SIZE=128):\n",
    "    batchCount = int(X_train.shape[0] / BATCH_SIZE)\n",
    "    print('Epochs:', epochs)\n",
    "    print('Batch size:', BATCH_SIZE)\n",
    "    print('Batches per epoch:', batchCount)\n",
    "    \n",
    "    for e in tqdm_notebook(range(1, epochs+1)):\n",
    "        if e == 1 or e%plt_frq == 0:\n",
    "            print('-'*15, 'Epoch %d' % e, '-'*15)\n",
    "        for _ in range(batchCount):  # tqdm_notebook(range(batchCount), leave=False):\n",
    "            # Create a batch by drawing random index numbers from the training set\n",
    "            image_batch = X_train[np.random.randint(0, X_train.shape[0], size=BATCH_SIZE)]\n",
    "            \n",
    "            # Create noise vectors for the generator\n",
    "            noise = np.random.normal(0, 1, size=(BATCH_SIZE, z_dim))\n",
    "            \n",
    "            # Generate the images from the noise\n",
    "            generated_images = g.predict(noise)\n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            \n",
    "            # Create Y labels similar to last exercise.\n",
    "            y1 = np.zeros(2*BATCH_SIZE)\n",
    "            y1[:BATCH_SIZE] =1 \n",
    "\n",
    "            # Train gan and disrciminator similar to last exercise.\n",
    "            ##YOUR CODE HERE###\n",
    "            d.trainable = True\n",
    "            d_loss = d.train_on_batch(X, y1)\n",
    "            \n",
    "            noise = np.random.normal(0, 1, size=(BATCH_SIZE, z_dim))\n",
    "            y2 = np.ones(BATCH_SIZE)\n",
    "            d.trainable = False\n",
    "            g_loss = gan.train_on_batch(noise, y2) \n",
    "\n",
    "        # Only store losses from final\n",
    "        losses[\"D\"].append(d_loss)\n",
    "        losses[\"G\"].append(g_loss)\n",
    "\n",
    "        # Update the plots\n",
    "        if e == 1 or e%plt_frq == 0:\n",
    "            plot_generated()\n",
    "    plot_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(epochs=200, plt_frq=40, BATCH_SIZE=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
